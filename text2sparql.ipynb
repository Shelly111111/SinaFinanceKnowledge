{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语义解析：基于seq2seq的text2sparql\n",
    "\n",
    "参考：[『NLP经典项目集』05：新年到，飞桨带你对对联](https://aistudio.baidu.com/aistudio/projectdetail/1321118)\n",
    "\n",
    "SPARQL的英文全称为SPARQL Protocol and RDF Query Language，是为RDF开发的一种查询语言和数据获取协议，它是为W3C所开发的RDF数据模型所定义，但是可以用于任何可以用RDF来表示的信息资源。它于2008年1月15日正式成为一项W3C推荐标准，于2013年3月发布SPARQL1.1。\n",
    "\n",
    "RDF的英语全称为Resource Description Framework，中文名称为资源描述框架。RDF是一种描述数据文件储存的数据模型，该数据模型通常描述由三个部分组成的事实，被称为三元组（triples）。三元组由主语（subject）、谓语（predicate）和宾语（object）组成，看上去很像一个简单的句子。\n",
    "\n",
    "\n",
    "这里，我们将根据自然语言，自动写sparql。这是一个典型的序列到序列(sequence2sequence, seq2seq）建模的场景，编码器-解码器（Encoder-Decoder）框架是解决seq2seq问题的经典方法，它能够将一个任意长度的源序列转换成另一个任意长度的目标序列：编码阶段将整个源序列编码成一个向量，解码阶段通过最大化预测序列概率，从中解码出整个目标序列。编码和解码的过程通常都使用RNN实现。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/e9dde4be7d0142068c5c921a1ca6a227a49aad4a8751425faead42f0348f5e01\" width=\"500\" height=\"313\" ></center>\n",
    "<br><center>图1：encoder-decoder示意图</center></br>\n",
    "\n",
    "\n",
    "这里的Encoder采用LSTM，Decoder采用带有attention机制的LSTM。 \n",
    "\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/a791fee76388423da867676d667b7d4c2fbe9fe9096843878c6513a40c96c86d\" width=\"500\" height=\"313\" ></center>\n",
    "<br><center>图2：带有attention机制的encoder-decoder示意图</center></br>\n",
    "\n",
    "我们将以自然语言问句作为Encoder的输出，sparql作为Decoder的输入，训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Studio平台默认安装了Paddle和PaddleNLP，并定期更新版本。 如需手动更新Paddle，可参考[飞桨安装说明](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/conda/linux-conda.html)，安装相应环境下最新版飞桨框架。\n",
    "\n",
    "使用如下命令确保安装最新版PaddleNLP："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:22.744340Z",
     "iopub.status.busy": "2022-06-24T05:58:22.744183Z",
     "iopub.status.idle": "2022-06-24T05:58:22.747072Z",
     "shell.execute_reply": "2022-06-24T05:58:22.746459Z",
     "shell.execute_reply.started": "2022-06-24T05:58:22.744319Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:22.748834Z",
     "iopub.status.busy": "2022-06-24T05:58:22.748458Z",
     "iopub.status.idle": "2022-06-24T05:58:24.629344Z",
     "shell.execute_reply": "2022-06-24T05:58:24.628608Z",
     "shell.execute_reply.started": "2022-06-24T05:58:22.748811Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.7'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddlenlp\n",
    "paddlenlp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:24.630479Z",
     "iopub.status.busy": "2022-06-24T05:58:24.630281Z",
     "iopub.status.idle": "2022-06-24T05:58:24.716915Z",
     "shell.execute_reply": "2022-06-24T05:58:24.716298Z",
     "shell.execute_reply.started": "2022-06-24T05:58:24.630457Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddlenlp.data import Vocab, Pad\n",
    "from paddlenlp.metrics import Perplexity\n",
    "from paddlenlp.datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据部分\n",
    "\n",
    "## 数据集介绍\n",
    "\n",
    "由于数据集不好生成，所以我这边只列了7条进行测试。\n",
    "\n",
    "数据如下：\n",
    "\n",
    "```\n",
    "煤炭行业有多少上市公司\tselect ( COUNT ( distinct ?result ) AS ?count ) where { ?n1 sct:hasChineseLabel \"煤炭行业\" . ?n1 rdfs: ?result . }\n",
    "乐凯胶片的股票id是多少\tselect ?result where { ?n1 sct:hasChineseLabel \"乐凯胶片\" . ?n1 sct:ID ?result . }\n",
    "太原重工属于哪个行业\tselect ?result where { ?n1 sct:hasChineseLabel ?result . ?n1 rdfs: ?n2 . ?n2 sct:hasChineseLabel \"太原重工\" . }\n",
    "上市公司最多的行业是什么\tselect ?result where { { select ?n1 ( count ( ?n2 ) as ?subresult ) where { zg:SinaFinance rdfs: ?n1 . ?n1 rdfs: ?n2 . } group by ?n1 } ?n1 sct:hasChineseLabel ?result . } order by desc ( ?subresult ) limit 1\n",
    "上市公司最少的5个行业是什么\tselect ?result where { { select ?n1 ( count ( ?n2 ) as ?subresult ) where { zg:SinaFinance rdfs: ?n1 . ?n1 rdfs: ?n2 . } group by ?n1 } ?n1 sct:hasChineseLabel ?result . } order by ?subresult limit 5\n",
    "上市公司最多的前3个行业的公司数目各是多少\tselect ?result where { select ( count ( ?n2 ) as ?result ) where { zg:SinaFinance rdfs: ?n1 . ?n1 rdfs: ?n2 . } group by ?n1 } order by desc ( ?result ) limit 3\n",
    "澳柯玛\tselect ?p ?result where { ?n1 sct:hasChineseLabel \"澳柯玛\" . ?n1 ?p ?result . }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集\n",
    "\n",
    "读入数据文件，这里将所有的输入数据全部转为小写统一格式，\n",
    "\n",
    "<br>\n",
    "\n",
    "- 获取数据集可以调用`paddlenlp.datasets.load_dataset`。其中train_ds为训练集，用于模型训练；由于数据量有些少，我将测试集test_ds设置为与train_ds一样，用于评估算法的性能，但不会根据测试集上的表现再去调整模型或参数。\n",
    "\n",
    "- 将生成的字典文件写入到data_dic.txt中保存，便于后台预测时读取调用。\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将数据集文本转成id\n",
    "使用jieba分词，然后将其映射成词向量，并拼接上开始和结束词。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/d6c36cfd88eb4d0d87884f6c9cd47e466c2b562411394606be6683af08733045\" width=\"200\" height=\"200\" ></center>\n",
    "<br><center>图3：token-to-id示意图</center></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:24.718426Z",
     "iopub.status.busy": "2022-06-24T05:58:24.717967Z",
     "iopub.status.idle": "2022-06-24T05:58:25.564411Z",
     "shell.execute_reply": "2022-06-24T05:58:25.563879Z",
     "shell.execute_reply.started": "2022-06-24T05:58:24.718394Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.830 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\"乐凯胶片\"': 3, '煤炭行业': 4, 'group': 5, 'desc': 6, '个': 7, '(': 8, '.': 9, '澳柯玛': 10, 'distinct': 11, '乐凯胶片': 12, 'count': 13, '?count': 14, '公司': 15, '重工': 16, '上市公司': 17, '的': 18, 'rdfs:': 19, '属于': 20, '1': 21, ')': 22, 'where': 23, '太原': 24, '\"太原重工\"': 25, '3': 26, 'sct:id': 27, '哪个': 28, 'order': 29, '最多': 30, '{': 31, '最少': 32, 'as': 33, 'zg:sinafinance': 34, '?n1': 35, '}': 36, 'sct:haschineselabel': 37, 'by': 38, '各是': 39, 'limit': 40, '数目': 41, '多少': 42, 'select': 43, '是': 44, '有': 45, '什么': 46, '?subresult': 47, '?n2': 48, '?p': 49, '\"澳柯玛\"': 50, '行业': 51, 'id': 52, '5': 53, '?result': 54, '股票': 55, '前': 56, '\"煤炭行业\"': 57}\n",
      "([1, 4, 45, 42, 17, 2], [1, 43, 8, 13, 8, 11, 54, 22, 33, 14, 22, 23, 31, 35, 37, 57, 9, 35, 19, 54, 9, 36, 2])\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import json\n",
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "\n",
    "pad_id = 2\n",
    "bos_id = 1\n",
    "eos_id = 2\n",
    "data_path='data.txt'\n",
    "data_dic_path = 'data_dic.txt'\n",
    "\n",
    "def get_id(vocab_dict, token):\n",
    "    return vocab_dict[token]\n",
    "\n",
    "with open(data_path,'r',encoding='utf-8') as fp:\n",
    "    lines=fp.readlines()\n",
    "    vocabs=[]\n",
    "    quers=[]\n",
    "    asws=[]\n",
    "    for line in lines:\n",
    "        line = line.lower() #全部转为小写\n",
    "        data=line.split('\\t')\n",
    "        quer=jieba.lcut(data[0].strip(), cut_all=False)\n",
    "        asw=data[1].strip().split(' ')\n",
    "        vocabs.extend(quer)\n",
    "        vocabs.extend(asw)\n",
    "        quers.append(quer)\n",
    "        asws.append(asw)\n",
    "    vocabs=list(set(vocabs))\n",
    "    vocab_dict={v:k+3 for k,v in enumerate(vocabs)}\n",
    "with open(data_dic_path,'w',encoding='utf-8') as fp:\n",
    "    data_dic=json.dumps(vocab_dict,ensure_ascii=False)\n",
    "    fp.write(data_dic)\n",
    "\n",
    "def read(data_path,quers,asws,vocab_dict):\n",
    "    for q,a in zip(quers,asws):\n",
    "        quer = [bos_id]+[get_id(vocab_dict, v) for v in q]+[eos_id]\n",
    "        asw = [bos_id]+[get_id(vocab_dict, v) for v in a]+[eos_id]\n",
    "        #train_ds.append(([bos_id]+quer+[eos_id],[bos_id]+asw+[eos_id]))\n",
    "        yield (quer, asw)\n",
    "train_ds = load_dataset(read, data_path=data_path, quers=quers, asws=asws, vocab_dict=vocab_dict, lazy=False)\n",
    "test_ds = train_ds\n",
    "vocab_size = len(vocabs)+3\n",
    "print(vocab_dict)\n",
    "print(train_ds[0])\n",
    "trg_idx2word = {k:v for v,k in vocab_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造dataloder\n",
    "\n",
    "使用`paddle.io.DataLoader`来创建训练和预测时所需要的`DataLoader`对象。\n",
    "\n",
    "`paddle.io.DataLoader`返回一个迭代器，该迭代器根据`batch_sampler`指定的顺序迭代返回dataset数据。支持单进程或多进程加载数据，快！\n",
    "\n",
    "<br>\n",
    "\n",
    "接收如下重要参数：\n",
    "-  `batch_sampler`：批采样器实例，用于在`paddle.io.DataLoader` 中迭代式获取mini-batch的样本下标数组，数组长度与 batch_size 一致。\n",
    "-  `collate_fn`：指定如何将样本列表组合为mini-batch数据。传给它参数需要是一个`callable`对象，需要实现对组建的batch的处理逻辑，并返回每个batch的数据。在这里传入的是`prepare_input`函数，对产生的数据进行pad操作，并返回实际长度等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PaddleNLP提供了许多NLP任务中，用于数据处理、组batch数据的相关API。\n",
    "\n",
    "| API                             | 简介                                       |\n",
    "| ------------------------------- | :----------------------------------------- |\n",
    "| `paddlenlp.data.Stack`          | 堆叠N个具有相同shape的输入数据来构建一个batch |\n",
    "| `paddlenlp.data.Pad`            | 将长度不同的多个句子padding到统一长度，取N个输入数据中的最大长度 |\n",
    "| `paddlenlp.data.Tuple`          | 将多个batchify函数包装在一起 |\n",
    "\n",
    "更多数据处理操作详见： [https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/data.md](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/data.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:25.565825Z",
     "iopub.status.busy": "2022-06-24T05:58:25.565372Z",
     "iopub.status.idle": "2022-06-24T05:58:25.571104Z",
     "shell.execute_reply": "2022-06-24T05:58:25.570602Z",
     "shell.execute_reply.started": "2022-06-24T05:58:25.565798Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_data_loader(dataset):\n",
    "    data_loader = paddle.io.DataLoader(\n",
    "        dataset,\n",
    "        batch_sampler=None,\n",
    "        batch_size = batch_size,\n",
    "        collate_fn=partial(prepare_input, pad_id=pad_id))\n",
    "    return data_loader\n",
    "\n",
    "def prepare_input(insts, pad_id):\n",
    "    src, src_length = Pad(pad_val=pad_id, ret_length=True)([inst[0] for inst in insts])\n",
    "    tgt, tgt_length = Pad(pad_val=pad_id, ret_length=True)([inst[1] for inst in insts])\n",
    "    tgt_mask = (tgt[:, :-1] != pad_id).astype(paddle.get_default_dtype())\n",
    "    #print(src, src_length, tgt[:, :-1], tgt[:, 1:, np.newaxis], tgt_mask)\n",
    "    return src, src_length, tgt[:, :-1], tgt[:, 1:, np.newaxis], tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:25.572269Z",
     "iopub.status.busy": "2022-06-24T05:58:25.571880Z",
     "iopub.status.idle": "2022-06-24T05:58:27.389364Z",
     "shell.execute_reply": "2022-06-24T05:58:27.388773Z",
     "shell.execute_reply.started": "2022-06-24T05:58:25.572246Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1 7\n",
      "5\n",
      "0 [7, 14]\n",
      "1 [7]\n",
      "2 [7, 44]\n",
      "3 [7, 44, 1]\n",
      "4 [7, 44]\n"
     ]
    }
   ],
   "source": [
    "device = \"gpu\" # or cpu\n",
    "device = paddle.set_device(device)\n",
    "\n",
    "batch_size = 7\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "hidden_size =256\n",
    "max_grad_norm = 5.0\n",
    "learning_rate = 0.001\n",
    "max_epoch = 300\n",
    "model_path = './couplet_models'\n",
    "log_freq = 2000\n",
    "\n",
    "# Define dataloader\n",
    "train_loader = create_data_loader(train_ds)\n",
    "test_loader = create_data_loader(test_ds)\n",
    "\n",
    "print(len(train_ds), len(train_loader), batch_size)\n",
    "# 7 1 7  共1个batch\n",
    "\n",
    "for i in train_loader:\n",
    "    print (len(i))\n",
    "    for ind, each in enumerate(i):\n",
    "        print (ind, each.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型部分\n",
    "下图是带有Attention的Seq2Seq模型结构。下面我们分别定义网络的每个部分，最后构建Seq2Seq主网络。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/8a9dda0434a14fb2a0837702e5f2f1096346810702aa4a6ab1fa7dafe548add6\" width=\"600\" height=\"600\" ></center>\n",
    "<br><center>图5：带有attention机制的encoder-decoder原理示意图</center></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义Encoder\n",
    "\n",
    "Encoder部分非常简单，可以直接利用PaddlePaddle2.0提供的RNN系列API的`nn.LSTM`。\n",
    "\n",
    "\n",
    "1. `nn.Embedding`：该接口用于构建 Embedding 的一个可调用对象，根据输入的size (vocab_size, embedding_dim)自动构造一个二维embedding矩阵，用于table-lookup。查表过程如下：\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/54276195f4ce44b9ace89c5153300782a744a98343454410898fcfe81333f131\" width=\"700\" height=\"600\" ></center>\n",
    "<br><center>图5：token-to-id & 查表获取向量示意图</center></br>\n",
    "\n",
    "2. `nn.LSTM`：提供序列，得到`encoder_output`和`encoder_state`。    \n",
    "参数：   \n",
    "- input_size (int) 输入的大小。\n",
    "- hidden_size (int) - 隐藏状态大小。\n",
    "- num_layers (int，可选) - 网络层数。默认为1。\n",
    "- direction (str，可选) - 网络迭代方向，可设置为forward或bidirect（或bidirectional）。默认为forward。\n",
    "- time_major (bool，可选) - 指定input的第一个维度是否是time steps。默认为False。\n",
    "- dropout (float，可选) - dropout概率，指的是出第一层外每层输入时的dropout概率。默认为0。\n",
    "\n",
    "[https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/layer/rnn/LSTM_cn.html](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/layer/rnn/LSTM_cn.html)\n",
    "\n",
    "\n",
    "输出:\n",
    "\n",
    "outputs (Tensor) - 输出，由前向和后向cell的输出拼接得到。如果time_major为True，则Tensor的形状为[time_steps,batch_size,num_directions * hidden_size]，如果time_major为False，则Tensor的形状为[batch_size,time_steps,num_directions * hidden_size]，当direction设置为bidirectional时，num_directions等于2，否则等于1。\n",
    "\n",
    "final_states (tuple) - 最终状态,一个包含h和c的元组。形状为[num_lauers * num_directions, batch_size, hidden_size],当direction设置为bidirectional时，num_directions等于2，否则等于1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:27.390854Z",
     "iopub.status.busy": "2022-06-24T05:58:27.390393Z",
     "iopub.status.idle": "2022-06-24T05:58:27.396115Z",
     "shell.execute_reply": "2022-06-24T05:58:27.395397Z",
     "shell.execute_reply.started": "2022-06-24T05:58:27.390826Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(nn.Layer):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers):\n",
    "        super(Seq2SeqEncoder, self).__init__()\n",
    "        self.embedder = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=0.2 if num_layers > 1 else 0.)\n",
    "\n",
    "    def forward(self, sequence, sequence_length):\n",
    "        inputs = self.embedder(sequence)\n",
    "        encoder_output, encoder_state = self.lstm(\n",
    "            inputs, sequence_length=sequence_length)\n",
    "        \n",
    "        # encoder_output [128, 18, 256]  [batch_size, time_steps, hidden_size]\n",
    "        # encoder_state (tuple) - 最终状态,一个包含h和c的元组。 [2, 128, 256] [2, 128, 256] [num_layers * num_directions, batch_size, hidden_size]\n",
    "        return encoder_output, encoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  定义AttentionLayer\n",
    "1. `nn.Linear`线性变换层传入2个参数   \n",
    "- in_features (int) – 线性变换层输入单元的数目。\n",
    "- out_features (int) – 线性变换层输出单元的数目。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4ce5851e5eab41af9733962d1782669dbef31a74540e468ab05b730ab2bb4ffc)\n",
    "\n",
    "2. `paddle.matmul`用于计算两个Tensor的乘积，遵循完整的广播规则，关于广播规则，请参考[广播 (broadcasting)](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/01_paddle2.0_introduction/basic_concept/broadcasting_cn.html#cn-user-guide-broadcasting) 。 并且其行为与 numpy.matmul 一致。  \n",
    "- x (Tensor) : 输入变量，类型为 Tensor，数据类型为float32， float64。\n",
    "- y (Tensor) : 输入变量，类型为 Tensor，数据类型为float32， float64。\n",
    "- transpose_x (bool，可选) : 相乘前是否转置 x，默认值为False。\n",
    "- transpose_y (bool，可选) : 相乘前是否转置 y，默认值为False。\n",
    "\n",
    "<br>\n",
    "\n",
    "3. `paddle.unsqueeze`用于向输入Tensor的Shape中一个或多个位置（axis）插入尺寸为1的维度\n",
    "\n",
    "4. `paddle.add`逐元素相加算子，输入 x 与输入 y 逐元素相加，并将各个位置的输出元素保存到返回结果中。\n",
    "\n",
    "输入 x 与输入 y 必须可以广播为相同形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:27.397163Z",
     "iopub.status.busy": "2022-06-24T05:58:27.396930Z",
     "iopub.status.idle": "2022-06-24T05:58:27.404480Z",
     "shell.execute_reply": "2022-06-24T05:58:27.403977Z",
     "shell.execute_reply.started": "2022-06-24T05:58:27.397140Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Layer):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.input_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output_proj = nn.Linear(hidden_size + hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, hidden, encoder_output, encoder_padding_mask):\n",
    "        encoder_output = self.input_proj(encoder_output)\n",
    "        attn_scores = paddle.matmul(\n",
    "            paddle.unsqueeze(hidden, [1]), encoder_output, transpose_y=True)\n",
    "        # print('attention score', attn_scores.shape) #[128, 1, 18]\n",
    "\n",
    "        if encoder_padding_mask is not None:\n",
    "            attn_scores = paddle.add(attn_scores, encoder_padding_mask)\n",
    "\n",
    "        attn_scores = F.softmax(attn_scores)\n",
    "        attn_out = paddle.squeeze(\n",
    "            paddle.matmul(attn_scores, encoder_output), [1])\n",
    "        # print('1 attn_out', attn_out.shape) #[128, 256]\n",
    "\n",
    "        attn_out = paddle.concat([attn_out, hidden], 1)\n",
    "        # print('2 attn_out', attn_out.shape) #[128, 512]\n",
    "\n",
    "        attn_out = self.output_proj(attn_out)\n",
    "        # print('3 attn_out', attn_out.shape) #[128, 256]\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义Seq2SeqDecoderCell\n",
    "由于Decoder部分是带有attention的LSTM，我们不能复用`nn.LSTM`，所以需要定义`Seq2SeqDecoderCell`\n",
    "\n",
    "1. `nn.LayerList` 用于保存子层列表，它包含的子层将被正确地注册和添加。列表中的子层可以像常规python列表一样被索引。这里添加了num_layers=2层lstm。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:27.405349Z",
     "iopub.status.busy": "2022-06-24T05:58:27.405192Z",
     "iopub.status.idle": "2022-06-24T05:58:27.412007Z",
     "shell.execute_reply": "2022-06-24T05:58:27.411320Z",
     "shell.execute_reply.started": "2022-06-24T05:58:27.405330Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqDecoderCell(nn.RNNCellBase):\n",
    "    def __init__(self, num_layers, input_size, hidden_size):\n",
    "        super(Seq2SeqDecoderCell, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lstm_cells = nn.LayerList([\n",
    "            nn.LSTMCell(\n",
    "                input_size=input_size + hidden_size if i == 0 else hidden_size,\n",
    "                hidden_size=hidden_size) for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.attention_layer = AttentionLayer(hidden_size)\n",
    "    \n",
    "    def forward(self,\n",
    "                step_input,\n",
    "                states,\n",
    "                encoder_output,\n",
    "                encoder_padding_mask=None):\n",
    "        lstm_states, input_feed = states\n",
    "        new_lstm_states = []\n",
    "        step_input = paddle.concat([step_input, input_feed], 1)\n",
    "        for i, lstm_cell in enumerate(self.lstm_cells):\n",
    "            out, new_lstm_state = lstm_cell(step_input, lstm_states[i])\n",
    "            step_input = self.dropout(out)\n",
    "            new_lstm_states.append(new_lstm_state)\n",
    "        out = self.attention_layer(step_input, encoder_output,\n",
    "                                   encoder_padding_mask)\n",
    "        return out, [new_lstm_states, out]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义Seq2SeqDecoder\n",
    "有了`Seq2SeqDecoderCell`，就可以构建`Seq2SeqDecoder`了\n",
    "\n",
    "<br>\n",
    "\n",
    "1. `paddle.nn.RNN` 该OP是循环神经网络（RNN）的封装，将输入的Cell封装为一个循环神经网络。它能够重复执行 cell.forward() 直到遍历完input中的所有Tensor。\n",
    "- cell (RNNCellBase) - RNNCellBase类的一个实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:27.413299Z",
     "iopub.status.busy": "2022-06-24T05:58:27.412890Z",
     "iopub.status.idle": "2022-06-24T05:58:27.418358Z",
     "shell.execute_reply": "2022-06-24T05:58:27.417726Z",
     "shell.execute_reply.started": "2022-06-24T05:58:27.413268Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(nn.Layer):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers):\n",
    "        super(Seq2SeqDecoder, self).__init__()\n",
    "        self.embedder = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm_attention = nn.RNN(\n",
    "            Seq2SeqDecoderCell(num_layers, embed_dim, hidden_size))\n",
    "        self.output_layer = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, trg, decoder_initial_states, encoder_output,\n",
    "                encoder_padding_mask):\n",
    "        inputs = self.embedder(trg)\n",
    "\n",
    "        decoder_output, _ = self.lstm_attention(\n",
    "            inputs,\n",
    "            initial_states=decoder_initial_states,\n",
    "            encoder_output=encoder_output,\n",
    "            encoder_padding_mask=encoder_padding_mask)\n",
    "        predict = self.output_layer(decoder_output)\n",
    "\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建主网络Seq2SeqAttnModel\n",
    "Encoder和Decoder定义好之后，网络就可以构建起来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:27.420817Z",
     "iopub.status.busy": "2022-06-24T05:58:27.420508Z",
     "iopub.status.idle": "2022-06-24T05:58:27.430925Z",
     "shell.execute_reply": "2022-06-24T05:58:27.430199Z",
     "shell.execute_reply.started": "2022-06-24T05:58:27.420794Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqAttnModel(nn.Layer):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers,\n",
    "                 eos_id=1):\n",
    "        super(Seq2SeqAttnModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.eos_id = eos_id\n",
    "        self.num_layers = num_layers\n",
    "        self.INF = 1e9\n",
    "        self.encoder = Seq2SeqEncoder(vocab_size, embed_dim, hidden_size,\n",
    "                                      num_layers)\n",
    "        self.decoder = Seq2SeqDecoder(vocab_size, embed_dim, hidden_size,\n",
    "                                      num_layers)\n",
    "\n",
    "    def forward(self, src, src_length, trg):\n",
    "        # encoder_output 各时刻的输出h\n",
    "        # encoder_final_state 最后时刻的输出h，和记忆信号c\n",
    "        encoder_output, encoder_final_state = self.encoder(src, src_length)\n",
    "        # print('encoder_output shape', encoder_output.shape)  #  [128, 18, 256]  [batch_size,time_steps,hidden_size]\n",
    "        # print('encoder_final_states shape', encoder_final_state[0].shape, encoder_final_state[1].shape) #[2, 128, 256] [2, 128, 256] [num_lauers * num_directions, batch_size, hidden_size]\n",
    "\n",
    "        # Transfer shape of encoder_final_states to [num_layers, 2, batch_size, hidden_size]？？？\n",
    "        encoder_final_states = [\n",
    "            (encoder_final_state[0][i], encoder_final_state[1][i])\n",
    "            for i in range(self.num_layers)\n",
    "        ]\n",
    "        # print('encoder_final_states shape', encoder_final_states[0][0].shape, encoder_final_states[0][1].shape) #[128, 256] [128, 256]\n",
    "\n",
    "\n",
    "        # Construct decoder initial states: use input_feed and the shape is\n",
    "        # [[h,c] * num_layers, input_feed], consistent with Seq2SeqDecoderCell.states\n",
    "        decoder_initial_states = [\n",
    "            encoder_final_states,\n",
    "            self.decoder.lstm_attention.cell.get_initial_states(\n",
    "                batch_ref=encoder_output, shape=[self.hidden_size])\n",
    "        ]\n",
    "\n",
    "        # Build attention mask to avoid paying attention on padddings\n",
    "        src_mask = (src != self.eos_id).astype(paddle.get_default_dtype())\n",
    "        # print ('src_mask shape', src_mask.shape)  #[128, 18]\n",
    "        # print(src_mask[0, :])\n",
    "\n",
    "        encoder_padding_mask = (src_mask - 1.0) * self.INF\n",
    "        # print ('encoder_padding_mask', encoder_padding_mask.shape)  #[128, 18]\n",
    "        # print(encoder_padding_mask[0, :])\n",
    "\n",
    "        encoder_padding_mask = paddle.unsqueeze(encoder_padding_mask, [1])\n",
    "        # print('encoder_padding_mask', encoder_padding_mask.shape)  #[128, 1, 18]\n",
    "\n",
    "        predict = self.decoder(trg, decoder_initial_states, encoder_output,\n",
    "                               encoder_padding_mask)\n",
    "        # print('predict', predict.shape)   #[128, 17, 7931]\n",
    "\n",
    "        return predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数\n",
    "这里使用的是交叉熵损失函数，我们需要将padding位置的loss置为0，因此需要在损失函数中引入`trg_mask`参数，由于PaddlePaddle框架提供的`paddle.nn.CrossEntropyLoss`不能接受`trg_mask`参数，因此在这里需要重新定义："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:27.432113Z",
     "iopub.status.busy": "2022-06-24T05:58:27.431644Z",
     "iopub.status.idle": "2022-06-24T05:58:27.436780Z",
     "shell.execute_reply": "2022-06-24T05:58:27.436214Z",
     "shell.execute_reply.started": "2022-06-24T05:58:27.432084Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CrossEntropyCriterion(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyCriterion, self).__init__()\n",
    "\n",
    "    def forward(self, predict, label, trg_mask):\n",
    "        cost = F.softmax_with_cross_entropy(\n",
    "            logits=predict, label=label, soft_label=False)\n",
    "        cost = paddle.squeeze(cost, axis=[2])\n",
    "        masked_cost = cost * trg_mask\n",
    "        batch_mean_cost = paddle.mean(masked_cost, axis=[0])\n",
    "        seq_cost = paddle.sum(batch_mean_cost)\n",
    "\n",
    "        return seq_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 执行过程\n",
    "## 训练过程\n",
    "使用高层API执行训练，需要调用`prepare`和`fit`函数。\n",
    "\n",
    "在`prepare`函数中，配置优化器、损失函数，以及评价指标。其中评价指标使用的是PaddleNLP提供的困惑度计算API `paddlenlp.metrics.Perplexity`。\n",
    "\n",
    "如果你安装了VisualDL，可以在fit中添加一个callbacks参数使用VisualDL观测你的训练过程，如下：\n",
    "\n",
    "``` python\n",
    "model.fit(train_data=train_loader,\n",
    "            epochs=max_epoch,\n",
    "            eval_freq=1,\n",
    "            save_freq=1,\n",
    "            save_dir=model_path,\n",
    "            log_freq=log_freq,\n",
    "            callbacks=[paddle.callbacks.VisualDL('./log')])\n",
    "```\n",
    "\n",
    "在这里，由于对联生成任务没有明确的评价指标，因此，可以在保存的多个模型中，通过人工评判生成结果选择最好的模型。\n",
    "\n",
    "本项目中，为了便于演示，已经将训练好的模型参数载入模型，并省略了训练过程。读者自己实验的时候，可以尝试自行修改超参数，调用下面被注释掉的`fit`函数，重新进行训练。\n",
    "\n",
    "如果读者想要在更短的时间内得到效果不错的模型，可以使用预训练模型技术，例如[《预训练模型ERNIE-GEN自动写诗》](https://aistudio.baidu.com/aistudio/projectdetail/1339888)项目为大家展示了如何利用预训练的生成模型进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:58:27.437902Z",
     "iopub.status.busy": "2022-06-24T05:58:27.437488Z",
     "iopub.status.idle": "2022-06-24T05:59:27.728591Z",
     "shell.execute_reply": "2022-06-24T05:59:27.727845Z",
     "shell.execute_reply.started": "2022-06-24T05:58:27.437876Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0624 13:58:27.441231   183 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0624 13:58:27.445106   183 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/300\n",
      "step 1/1 - loss: 110.5153 - Perplexity: 57.4147 - 171ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/0\n",
      "Epoch 2/300\n",
      "step 1/1 - loss: 107.7036 - Perplexity: 51.7929 - 149ms/step\n",
      "Epoch 3/300\n",
      "step 1/1 - loss: 104.2128 - Perplexity: 45.5730 - 140ms/step\n",
      "Epoch 4/300\n",
      "step 1/1 - loss: 98.4705 - Perplexity: 36.9241 - 135ms/step\n",
      "Epoch 5/300\n",
      "step 1/1 - loss: 96.6868 - Perplexity: 34.5876 - 124ms/step\n",
      "Epoch 6/300\n",
      "step 1/1 - loss: 90.1235 - Perplexity: 27.1928 - 127ms/step\n",
      "Epoch 7/300\n",
      "step 1/1 - loss: 89.0746 - Perplexity: 26.1674 - 127ms/step\n",
      "Epoch 8/300\n",
      "step 1/1 - loss: 87.7988 - Perplexity: 24.9720 - 134ms/step\n",
      "Epoch 9/300\n",
      "step 1/1 - loss: 86.2980 - Perplexity: 23.6356 - 127ms/step\n",
      "Epoch 10/300\n",
      "step 1/1 - loss: 84.0344 - Perplexity: 21.7540 - 132ms/step\n",
      "Epoch 11/300\n",
      "step 1/1 - loss: 81.8703 - Perplexity: 20.0952 - 140ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/10\n",
      "Epoch 12/300\n",
      "step 1/1 - loss: 79.9658 - Perplexity: 18.7404 - 140ms/step\n",
      "Epoch 13/300\n",
      "step 1/1 - loss: 79.0114 - Perplexity: 18.0962 - 131ms/step\n",
      "Epoch 14/300\n",
      "step 1/1 - loss: 78.4972 - Perplexity: 17.7584 - 130ms/step\n",
      "Epoch 15/300\n",
      "step 1/1 - loss: 78.4520 - Perplexity: 17.7290 - 130ms/step\n",
      "Epoch 16/300\n",
      "step 1/1 - loss: 77.8340 - Perplexity: 17.3320 - 129ms/step\n",
      "Epoch 17/300\n",
      "step 1/1 - loss: 76.3526 - Perplexity: 16.4161 - 132ms/step\n",
      "Epoch 18/300\n",
      "step 1/1 - loss: 76.2285 - Perplexity: 16.3416 - 131ms/step\n",
      "Epoch 19/300\n",
      "step 1/1 - loss: 75.0483 - Perplexity: 15.6499 - 122ms/step\n",
      "Epoch 20/300\n",
      "step 1/1 - loss: 74.7979 - Perplexity: 15.5069 - 131ms/step\n",
      "Epoch 21/300\n",
      "step 1/1 - loss: 73.3243 - Perplexity: 14.6916 - 130ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/20\n",
      "Epoch 22/300\n",
      "step 1/1 - loss: 72.3674 - Perplexity: 14.1853 - 132ms/step\n",
      "Epoch 23/300\n",
      "step 1/1 - loss: 71.5230 - Perplexity: 13.7530 - 125ms/step\n",
      "Epoch 24/300\n",
      "step 1/1 - loss: 70.8801 - Perplexity: 13.4328 - 125ms/step\n",
      "Epoch 25/300\n",
      "step 1/1 - loss: 69.2421 - Perplexity: 12.6502 - 128ms/step\n",
      "Epoch 26/300\n",
      "step 1/1 - loss: 68.8609 - Perplexity: 12.4747 - 122ms/step\n",
      "Epoch 27/300\n",
      "step 1/1 - loss: 66.8073 - Perplexity: 11.5702 - 134ms/step\n",
      "Epoch 28/300\n",
      "step 1/1 - loss: 66.3903 - Perplexity: 11.3948 - 140ms/step\n",
      "Epoch 29/300\n",
      "step 1/1 - loss: 64.9062 - Perplexity: 10.7915 - 129ms/step\n",
      "Epoch 30/300\n",
      "step 1/1 - loss: 64.1167 - Perplexity: 10.4838 - 126ms/step\n",
      "Epoch 31/300\n",
      "step 1/1 - loss: 64.2616 - Perplexity: 10.5396 - 131ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/30\n",
      "Epoch 32/300\n",
      "step 1/1 - loss: 62.9287 - Perplexity: 10.0371 - 139ms/step\n",
      "Epoch 33/300\n",
      "step 1/1 - loss: 60.2776 - Perplexity: 9.1078 - 129ms/step\n",
      "Epoch 34/300\n",
      "step 1/1 - loss: 60.0526 - Perplexity: 9.0329 - 128ms/step\n",
      "Epoch 35/300\n",
      "step 1/1 - loss: 58.6252 - Perplexity: 8.5726 - 134ms/step\n",
      "Epoch 36/300\n",
      "step 1/1 - loss: 56.5749 - Perplexity: 7.9520 - 132ms/step\n",
      "Epoch 37/300\n",
      "step 1/1 - loss: 55.9000 - Perplexity: 7.7578 - 123ms/step\n",
      "Epoch 38/300\n",
      "step 1/1 - loss: 54.3263 - Perplexity: 7.3230 - 123ms/step\n",
      "Epoch 39/300\n",
      "step 1/1 - loss: 53.0880 - Perplexity: 6.9981 - 128ms/step\n",
      "Epoch 40/300\n",
      "step 1/1 - loss: 52.6260 - Perplexity: 6.8806 - 121ms/step\n",
      "Epoch 41/300\n",
      "step 1/1 - loss: 50.4895 - Perplexity: 6.3624 - 131ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/40\n",
      "Epoch 42/300\n",
      "step 1/1 - loss: 49.6638 - Perplexity: 6.1727 - 144ms/step\n",
      "Epoch 43/300\n",
      "step 1/1 - loss: 48.2199 - Perplexity: 5.8546 - 137ms/step\n",
      "Epoch 44/300\n",
      "step 1/1 - loss: 46.6616 - Perplexity: 5.5296 - 125ms/step\n",
      "Epoch 45/300\n",
      "step 1/1 - loss: 46.0195 - Perplexity: 5.4010 - 136ms/step\n",
      "Epoch 46/300\n",
      "step 1/1 - loss: 44.4164 - Perplexity: 5.0928 - 130ms/step\n",
      "Epoch 47/300\n",
      "step 1/1 - loss: 42.9654 - Perplexity: 4.8290 - 129ms/step\n",
      "Epoch 48/300\n",
      "step 1/1 - loss: 41.3929 - Perplexity: 4.5586 - 137ms/step\n",
      "Epoch 49/300\n",
      "step 1/1 - loss: 40.2772 - Perplexity: 4.3760 - 132ms/step\n",
      "Epoch 50/300\n",
      "step 1/1 - loss: 38.9075 - Perplexity: 4.1617 - 131ms/step\n",
      "Epoch 51/300\n",
      "step 1/1 - loss: 42.1174 - Perplexity: 4.6813 - 133ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/50\n",
      "Epoch 52/300\n",
      "step 1/1 - loss: 39.6045 - Perplexity: 4.2694 - 134ms/step\n",
      "Epoch 53/300\n",
      "step 1/1 - loss: 36.3269 - Perplexity: 3.7862 - 128ms/step\n",
      "Epoch 54/300\n",
      "step 1/1 - loss: 35.9506 - Perplexity: 3.7343 - 135ms/step\n",
      "Epoch 55/300\n",
      "step 1/1 - loss: 36.3335 - Perplexity: 3.7871 - 136ms/step\n",
      "Epoch 56/300\n",
      "step 1/1 - loss: 32.9537 - Perplexity: 3.3459 - 139ms/step\n",
      "Epoch 57/300\n",
      "step 1/1 - loss: 32.1126 - Perplexity: 3.2443 - 143ms/step\n",
      "Epoch 58/300\n",
      "step 1/1 - loss: 32.1041 - Perplexity: 3.2433 - 166ms/step\n",
      "Epoch 59/300\n",
      "step 1/1 - loss: 30.8287 - Perplexity: 3.0952 - 136ms/step\n",
      "Epoch 60/300\n",
      "step 1/1 - loss: 29.6371 - Perplexity: 2.9629 - 137ms/step\n",
      "Epoch 61/300\n",
      "step 1/1 - loss: 29.2966 - Perplexity: 2.9262 - 132ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/60\n",
      "Epoch 62/300\n",
      "step 1/1 - loss: 27.7913 - Perplexity: 2.7691 - 143ms/step\n",
      "Epoch 63/300\n",
      "step 1/1 - loss: 27.2458 - Perplexity: 2.7143 - 139ms/step\n",
      "Epoch 64/300\n",
      "step 1/1 - loss: 25.0721 - Perplexity: 2.5065 - 136ms/step\n",
      "Epoch 65/300\n",
      "step 1/1 - loss: 24.8279 - Perplexity: 2.4841 - 135ms/step\n",
      "Epoch 66/300\n",
      "step 1/1 - loss: 24.9437 - Perplexity: 2.4947 - 137ms/step\n",
      "Epoch 67/300\n",
      "step 1/1 - loss: 22.4061 - Perplexity: 2.2731 - 135ms/step\n",
      "Epoch 68/300\n",
      "step 1/1 - loss: 20.1074 - Perplexity: 2.0895 - 133ms/step\n",
      "Epoch 69/300\n",
      "step 1/1 - loss: 20.3457 - Perplexity: 2.1078 - 134ms/step\n",
      "Epoch 70/300\n",
      "step 1/1 - loss: 20.6863 - Perplexity: 2.1343 - 130ms/step\n",
      "Epoch 71/300\n",
      "step 1/1 - loss: 17.9480 - Perplexity: 1.9305 - 132ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/70\n",
      "Epoch 72/300\n",
      "step 1/1 - loss: 18.2761 - Perplexity: 1.9539 - 142ms/step\n",
      "Epoch 73/300\n",
      "step 1/1 - loss: 18.4646 - Perplexity: 1.9674 - 137ms/step\n",
      "Epoch 74/300\n",
      "step 1/1 - loss: 21.0993 - Perplexity: 2.1668 - 138ms/step\n",
      "Epoch 75/300\n",
      "step 1/1 - loss: 25.0893 - Perplexity: 2.5080 - 136ms/step\n",
      "Epoch 76/300\n",
      "step 1/1 - loss: 16.7222 - Perplexity: 1.8457 - 134ms/step\n",
      "Epoch 77/300\n",
      "step 1/1 - loss: 20.7931 - Perplexity: 2.1427 - 138ms/step\n",
      "Epoch 78/300\n",
      "step 1/1 - loss: 15.3936 - Perplexity: 1.7580 - 135ms/step\n",
      "Epoch 79/300\n",
      "step 1/1 - loss: 16.2948 - Perplexity: 1.8170 - 133ms/step\n",
      "Epoch 80/300\n",
      "step 1/1 - loss: 16.3141 - Perplexity: 1.8183 - 135ms/step\n",
      "Epoch 81/300\n",
      "step 1/1 - loss: 13.9432 - Perplexity: 1.6670 - 155ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/80\n",
      "Epoch 82/300\n",
      "step 1/1 - loss: 15.1515 - Perplexity: 1.7424 - 145ms/step\n",
      "Epoch 83/300\n",
      "step 1/1 - loss: 13.9827 - Perplexity: 1.6694 - 139ms/step\n",
      "Epoch 84/300\n",
      "step 1/1 - loss: 12.0562 - Perplexity: 1.5556 - 139ms/step\n",
      "Epoch 85/300\n",
      "step 1/1 - loss: 13.1181 - Perplexity: 1.6173 - 134ms/step\n",
      "Epoch 86/300\n",
      "step 1/1 - loss: 12.0527 - Perplexity: 1.5554 - 139ms/step\n",
      "Epoch 87/300\n",
      "step 1/1 - loss: 11.8395 - Perplexity: 1.5433 - 136ms/step\n",
      "Epoch 88/300\n",
      "step 1/1 - loss: 11.4592 - Perplexity: 1.5219 - 133ms/step\n",
      "Epoch 89/300\n",
      "step 1/1 - loss: 10.2598 - Perplexity: 1.4565 - 139ms/step\n",
      "Epoch 90/300\n",
      "step 1/1 - loss: 10.3996 - Perplexity: 1.4639 - 137ms/step\n",
      "Epoch 91/300\n",
      "step 1/1 - loss: 9.4878 - Perplexity: 1.4158 - 133ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/90\n",
      "Epoch 92/300\n",
      "step 1/1 - loss: 8.0629 - Perplexity: 1.3438 - 140ms/step\n",
      "Epoch 93/300\n",
      "step 1/1 - loss: 8.3744 - Perplexity: 1.3592 - 131ms/step\n",
      "Epoch 94/300\n",
      "step 1/1 - loss: 7.7373 - Perplexity: 1.3279 - 135ms/step\n",
      "Epoch 95/300\n",
      "step 1/1 - loss: 7.6987 - Perplexity: 1.3260 - 136ms/step\n",
      "Epoch 96/300\n",
      "step 1/1 - loss: 7.3876 - Perplexity: 1.3109 - 135ms/step\n",
      "Epoch 97/300\n",
      "step 1/1 - loss: 6.7002 - Perplexity: 1.2783 - 146ms/step\n",
      "Epoch 98/300\n",
      "step 1/1 - loss: 6.9685 - Perplexity: 1.2910 - 133ms/step\n",
      "Epoch 99/300\n",
      "step 1/1 - loss: 5.9433 - Perplexity: 1.2434 - 131ms/step\n",
      "Epoch 100/300\n",
      "step 1/1 - loss: 6.1124 - Perplexity: 1.2511 - 135ms/step\n",
      "Epoch 101/300\n",
      "step 1/1 - loss: 6.1497 - Perplexity: 1.2528 - 136ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/100\n",
      "Epoch 102/300\n",
      "step 1/1 - loss: 5.3174 - Perplexity: 1.2152 - 159ms/step\n",
      "Epoch 103/300\n",
      "step 1/1 - loss: 5.6222 - Perplexity: 1.2288 - 152ms/step\n",
      "Epoch 104/300\n",
      "step 1/1 - loss: 4.7257 - Perplexity: 1.1891 - 145ms/step\n",
      "Epoch 105/300\n",
      "step 1/1 - loss: 5.0212 - Perplexity: 1.2020 - 129ms/step\n",
      "Epoch 106/300\n",
      "step 1/1 - loss: 4.7482 - Perplexity: 1.1901 - 135ms/step\n",
      "Epoch 107/300\n",
      "step 1/1 - loss: 4.5242 - Perplexity: 1.1803 - 135ms/step\n",
      "Epoch 108/300\n",
      "step 1/1 - loss: 4.1860 - Perplexity: 1.1658 - 154ms/step\n",
      "Epoch 109/300\n",
      "step 1/1 - loss: 4.0830 - Perplexity: 1.1614 - 133ms/step\n",
      "Epoch 110/300\n",
      "step 1/1 - loss: 4.3849 - Perplexity: 1.1743 - 133ms/step\n",
      "Epoch 111/300\n",
      "step 1/1 - loss: 3.5687 - Perplexity: 1.1397 - 128ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/110\n",
      "Epoch 112/300\n",
      "step 1/1 - loss: 3.8254 - Perplexity: 1.1505 - 136ms/step\n",
      "Epoch 113/300\n",
      "step 1/1 - loss: 3.1867 - Perplexity: 1.1239 - 134ms/step\n",
      "Epoch 114/300\n",
      "step 1/1 - loss: 3.5134 - Perplexity: 1.1374 - 134ms/step\n",
      "Epoch 115/300\n",
      "step 1/1 - loss: 3.0096 - Perplexity: 1.1166 - 128ms/step\n",
      "Epoch 116/300\n",
      "step 1/1 - loss: 3.0013 - Perplexity: 1.1163 - 123ms/step\n",
      "Epoch 117/300\n",
      "step 1/1 - loss: 2.9199 - Perplexity: 1.1129 - 129ms/step\n",
      "Epoch 118/300\n",
      "step 1/1 - loss: 2.6077 - Perplexity: 1.1003 - 126ms/step\n",
      "Epoch 119/300\n",
      "step 1/1 - loss: 3.1273 - Perplexity: 1.1214 - 128ms/step\n",
      "Epoch 120/300\n",
      "step 1/1 - loss: 2.8213 - Perplexity: 1.1089 - 124ms/step\n",
      "Epoch 121/300\n",
      "step 1/1 - loss: 2.2680 - Perplexity: 1.0867 - 137ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/120\n",
      "Epoch 122/300\n",
      "step 1/1 - loss: 2.5121 - Perplexity: 1.0964 - 145ms/step\n",
      "Epoch 123/300\n",
      "step 1/1 - loss: 2.5465 - Perplexity: 1.0978 - 134ms/step\n",
      "Epoch 124/300\n",
      "step 1/1 - loss: 2.0784 - Perplexity: 1.0791 - 125ms/step\n",
      "Epoch 125/300\n",
      "step 1/1 - loss: 2.6353 - Perplexity: 1.1014 - 136ms/step\n",
      "Epoch 126/300\n",
      "step 1/1 - loss: 2.6956 - Perplexity: 1.1038 - 134ms/step\n",
      "Epoch 127/300\n",
      "step 1/1 - loss: 2.3009 - Perplexity: 1.0880 - 128ms/step\n",
      "Epoch 128/300\n",
      "step 1/1 - loss: 2.1123 - Perplexity: 1.0805 - 128ms/step\n",
      "Epoch 129/300\n",
      "step 1/1 - loss: 1.9642 - Perplexity: 1.0746 - 231ms/step\n",
      "Epoch 130/300\n",
      "step 1/1 - loss: 2.0477 - Perplexity: 1.0779 - 124ms/step\n",
      "Epoch 131/300\n",
      "step 1/1 - loss: 1.8583 - Perplexity: 1.0705 - 128ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/130\n",
      "Epoch 132/300\n",
      "step 1/1 - loss: 2.0076 - Perplexity: 1.0764 - 139ms/step\n",
      "Epoch 133/300\n",
      "step 1/1 - loss: 1.8660 - Perplexity: 1.0708 - 126ms/step\n",
      "Epoch 134/300\n",
      "step 1/1 - loss: 1.7071 - Perplexity: 1.0646 - 125ms/step\n",
      "Epoch 135/300\n",
      "step 1/1 - loss: 1.6822 - Perplexity: 1.0636 - 123ms/step\n",
      "Epoch 136/300\n",
      "step 1/1 - loss: 2.0304 - Perplexity: 1.0773 - 121ms/step\n",
      "Epoch 137/300\n",
      "step 1/1 - loss: 1.3360 - Perplexity: 1.0502 - 133ms/step\n",
      "Epoch 138/300\n",
      "step 1/1 - loss: 1.6488 - Perplexity: 1.0623 - 130ms/step\n",
      "Epoch 139/300\n",
      "step 1/1 - loss: 1.6456 - Perplexity: 1.0622 - 123ms/step\n",
      "Epoch 140/300\n",
      "step 1/1 - loss: 1.6471 - Perplexity: 1.0622 - 126ms/step\n",
      "Epoch 141/300\n",
      "step 1/1 - loss: 1.4193 - Perplexity: 1.0534 - 122ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/140\n",
      "Epoch 142/300\n",
      "step 1/1 - loss: 1.4592 - Perplexity: 1.0549 - 137ms/step\n",
      "Epoch 143/300\n",
      "step 1/1 - loss: 1.1460 - Perplexity: 1.0429 - 124ms/step\n",
      "Epoch 144/300\n",
      "step 1/1 - loss: 2.7473 - Perplexity: 1.1059 - 129ms/step\n",
      "Epoch 145/300\n",
      "step 1/1 - loss: 1.9069 - Perplexity: 1.0724 - 136ms/step\n",
      "Epoch 146/300\n",
      "step 1/1 - loss: 2.0672 - Perplexity: 1.0787 - 134ms/step\n",
      "Epoch 147/300\n",
      "step 1/1 - loss: 2.5867 - Perplexity: 1.0994 - 131ms/step\n",
      "Epoch 148/300\n",
      "step 1/1 - loss: 7.1691 - Perplexity: 1.3005 - 124ms/step\n",
      "Epoch 149/300\n",
      "step 1/1 - loss: 1.7934 - Perplexity: 1.0679 - 160ms/step\n",
      "Epoch 150/300\n",
      "step 1/1 - loss: 2.4348 - Perplexity: 1.0933 - 157ms/step\n",
      "Epoch 151/300\n",
      "step 1/1 - loss: 1.7943 - Perplexity: 1.0680 - 133ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/150\n",
      "Epoch 152/300\n",
      "step 1/1 - loss: 1.8028 - Perplexity: 1.0683 - 134ms/step\n",
      "Epoch 153/300\n",
      "step 1/1 - loss: 1.6378 - Perplexity: 1.0619 - 131ms/step\n",
      "Epoch 154/300\n",
      "step 1/1 - loss: 2.1659 - Perplexity: 1.0826 - 121ms/step\n",
      "Epoch 155/300\n",
      "step 1/1 - loss: 1.6965 - Perplexity: 1.0642 - 122ms/step\n",
      "Epoch 156/300\n",
      "step 1/1 - loss: 1.6470 - Perplexity: 1.0622 - 126ms/step\n",
      "Epoch 157/300\n",
      "step 1/1 - loss: 2.0402 - Perplexity: 1.0776 - 129ms/step\n",
      "Epoch 158/300\n",
      "step 1/1 - loss: 1.7195 - Perplexity: 1.0650 - 125ms/step\n",
      "Epoch 159/300\n",
      "step 1/1 - loss: 1.5897 - Perplexity: 1.0600 - 126ms/step\n",
      "Epoch 160/300\n",
      "step 1/1 - loss: 1.4215 - Perplexity: 1.0535 - 129ms/step\n",
      "Epoch 161/300\n",
      "step 1/1 - loss: 1.3219 - Perplexity: 1.0496 - 121ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/160\n",
      "Epoch 162/300\n",
      "step 1/1 - loss: 1.3845 - Perplexity: 1.0521 - 137ms/step\n",
      "Epoch 163/300\n",
      "step 1/1 - loss: 1.1884 - Perplexity: 1.0445 - 132ms/step\n",
      "Epoch 164/300\n",
      "step 1/1 - loss: 1.7092 - Perplexity: 1.0646 - 132ms/step\n",
      "Epoch 165/300\n",
      "step 1/1 - loss: 1.7183 - Perplexity: 1.0650 - 134ms/step\n",
      "Epoch 166/300\n",
      "step 1/1 - loss: 0.9294 - Perplexity: 1.0346 - 130ms/step\n",
      "Epoch 167/300\n",
      "step 1/1 - loss: 1.3195 - Perplexity: 1.0495 - 124ms/step\n",
      "Epoch 168/300\n",
      "step 1/1 - loss: 3.2692 - Perplexity: 1.1273 - 130ms/step\n",
      "Epoch 169/300\n",
      "step 1/1 - loss: 10.6258 - Perplexity: 1.4761 - 128ms/step\n",
      "Epoch 170/300\n",
      "step 1/1 - loss: 5.7919 - Perplexity: 1.2365 - 123ms/step\n",
      "Epoch 171/300\n",
      "step 1/1 - loss: 5.6185 - Perplexity: 1.2286 - 126ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/170\n",
      "Epoch 172/300\n",
      "step 1/1 - loss: 5.4458 - Perplexity: 1.2209 - 139ms/step\n",
      "Epoch 173/300\n",
      "step 1/1 - loss: 3.6529 - Perplexity: 1.1433 - 133ms/step\n",
      "Epoch 174/300\n",
      "step 1/1 - loss: 4.8726 - Perplexity: 1.1955 - 135ms/step\n",
      "Epoch 175/300\n",
      "step 1/1 - loss: 4.0565 - Perplexity: 1.1603 - 130ms/step\n",
      "Epoch 176/300\n",
      "step 1/1 - loss: 3.1626 - Perplexity: 1.1229 - 134ms/step\n",
      "Epoch 177/300\n",
      "step 1/1 - loss: 4.5031 - Perplexity: 1.1794 - 133ms/step\n",
      "Epoch 178/300\n",
      "step 1/1 - loss: 3.6115 - Perplexity: 1.1415 - 128ms/step\n",
      "Epoch 179/300\n",
      "step 1/1 - loss: 4.4363 - Perplexity: 1.1766 - 138ms/step\n",
      "Epoch 180/300\n",
      "step 1/1 - loss: 3.6072 - Perplexity: 1.1413 - 131ms/step\n",
      "Epoch 181/300\n",
      "step 1/1 - loss: 4.2331 - Perplexity: 1.1678 - 121ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/180\n",
      "Epoch 182/300\n",
      "step 1/1 - loss: 3.4309 - Perplexity: 1.1340 - 139ms/step\n",
      "Epoch 183/300\n",
      "step 1/1 - loss: 2.9524 - Perplexity: 1.1143 - 128ms/step\n",
      "Epoch 184/300\n",
      "step 1/1 - loss: 2.5763 - Perplexity: 1.0990 - 124ms/step\n",
      "Epoch 185/300\n",
      "step 1/1 - loss: 2.9158 - Perplexity: 1.1128 - 124ms/step\n",
      "Epoch 186/300\n",
      "step 1/1 - loss: 2.8919 - Perplexity: 1.1118 - 127ms/step\n",
      "Epoch 187/300\n",
      "step 1/1 - loss: 2.1593 - Perplexity: 1.0824 - 124ms/step\n",
      "Epoch 188/300\n",
      "step 1/1 - loss: 2.6743 - Perplexity: 1.1030 - 121ms/step\n",
      "Epoch 189/300\n",
      "step 1/1 - loss: 2.4247 - Perplexity: 1.0929 - 127ms/step\n",
      "Epoch 190/300\n",
      "step 1/1 - loss: 2.0457 - Perplexity: 1.0779 - 123ms/step\n",
      "Epoch 191/300\n",
      "step 1/1 - loss: 1.7202 - Perplexity: 1.0651 - 120ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/190\n",
      "Epoch 192/300\n",
      "step 1/1 - loss: 1.8292 - Perplexity: 1.0693 - 137ms/step\n",
      "Epoch 193/300\n",
      "step 1/1 - loss: 1.8922 - Perplexity: 1.0718 - 129ms/step\n",
      "Epoch 194/300\n",
      "step 1/1 - loss: 1.6628 - Perplexity: 1.0628 - 133ms/step\n",
      "Epoch 195/300\n",
      "step 1/1 - loss: 3.6463 - Perplexity: 1.1430 - 137ms/step\n",
      "Epoch 196/300\n",
      "step 1/1 - loss: 2.3573 - Perplexity: 1.0902 - 140ms/step\n",
      "Epoch 197/300\n",
      "step 1/1 - loss: 2.2412 - Perplexity: 1.0856 - 131ms/step\n",
      "Epoch 198/300\n",
      "step 1/1 - loss: 2.3819 - Perplexity: 1.0912 - 135ms/step\n",
      "Epoch 199/300\n",
      "step 1/1 - loss: 2.2035 - Perplexity: 1.0841 - 128ms/step\n",
      "Epoch 200/300\n",
      "step 1/1 - loss: 2.7352 - Perplexity: 1.1054 - 133ms/step\n",
      "Epoch 201/300\n",
      "step 1/1 - loss: 1.9057 - Perplexity: 1.0723 - 131ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/200\n",
      "Epoch 202/300\n",
      "step 1/1 - loss: 1.8118 - Perplexity: 1.0687 - 137ms/step\n",
      "Epoch 203/300\n",
      "step 1/1 - loss: 3.4597 - Perplexity: 1.1352 - 130ms/step\n",
      "Epoch 204/300\n",
      "step 1/1 - loss: 1.7576 - Perplexity: 1.0665 - 140ms/step\n",
      "Epoch 205/300\n",
      "step 1/1 - loss: 2.1946 - Perplexity: 1.0838 - 135ms/step\n",
      "Epoch 206/300\n",
      "step 1/1 - loss: 2.0603 - Perplexity: 1.0784 - 128ms/step\n",
      "Epoch 207/300\n",
      "step 1/1 - loss: 1.4388 - Perplexity: 1.0541 - 132ms/step\n",
      "Epoch 208/300\n",
      "step 1/1 - loss: 1.6410 - Perplexity: 1.0620 - 134ms/step\n",
      "Epoch 209/300\n",
      "step 1/1 - loss: 1.5816 - Perplexity: 1.0597 - 135ms/step\n",
      "Epoch 210/300\n",
      "step 1/1 - loss: 1.5891 - Perplexity: 1.0600 - 136ms/step\n",
      "Epoch 211/300\n",
      "step 1/1 - loss: 2.0034 - Perplexity: 1.0762 - 129ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/210\n",
      "Epoch 212/300\n",
      "step 1/1 - loss: 1.4478 - Perplexity: 1.0545 - 143ms/step\n",
      "Epoch 213/300\n",
      "step 1/1 - loss: 1.3512 - Perplexity: 1.0508 - 132ms/step\n",
      "Epoch 214/300\n",
      "step 1/1 - loss: 1.2488 - Perplexity: 1.0468 - 130ms/step\n",
      "Epoch 215/300\n",
      "step 1/1 - loss: 1.0574 - Perplexity: 1.0395 - 136ms/step\n",
      "Epoch 216/300\n",
      "step 1/1 - loss: 1.0303 - Perplexity: 1.0385 - 129ms/step\n",
      "Epoch 217/300\n",
      "step 1/1 - loss: 1.0180 - Perplexity: 1.0380 - 133ms/step\n",
      "Epoch 218/300\n",
      "step 1/1 - loss: 1.3869 - Perplexity: 1.0521 - 136ms/step\n",
      "Epoch 219/300\n",
      "step 1/1 - loss: 0.9113 - Perplexity: 1.0340 - 134ms/step\n",
      "Epoch 220/300\n",
      "step 1/1 - loss: 0.9637 - Perplexity: 1.0359 - 127ms/step\n",
      "Epoch 221/300\n",
      "step 1/1 - loss: 1.3272 - Perplexity: 1.0498 - 128ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/220\n",
      "Epoch 222/300\n",
      "step 1/1 - loss: 0.7928 - Perplexity: 1.0295 - 139ms/step\n",
      "Epoch 223/300\n",
      "step 1/1 - loss: 0.7540 - Perplexity: 1.0280 - 132ms/step\n",
      "Epoch 224/300\n",
      "step 1/1 - loss: 0.9917 - Perplexity: 1.0370 - 133ms/step\n",
      "Epoch 225/300\n",
      "step 1/1 - loss: 0.7598 - Perplexity: 1.0282 - 132ms/step\n",
      "Epoch 226/300\n",
      "step 1/1 - loss: 1.1145 - Perplexity: 1.0417 - 132ms/step\n",
      "Epoch 227/300\n",
      "step 1/1 - loss: 0.8210 - Perplexity: 1.0305 - 137ms/step\n",
      "Epoch 228/300\n",
      "step 1/1 - loss: 0.8350 - Perplexity: 1.0311 - 131ms/step\n",
      "Epoch 229/300\n",
      "step 1/1 - loss: 0.5354 - Perplexity: 1.0198 - 128ms/step\n",
      "Epoch 230/300\n",
      "step 1/1 - loss: 0.7964 - Perplexity: 1.0296 - 132ms/step\n",
      "Epoch 231/300\n",
      "step 1/1 - loss: 0.6573 - Perplexity: 1.0244 - 130ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/230\n",
      "Epoch 232/300\n",
      "step 1/1 - loss: 0.4707 - Perplexity: 1.0174 - 146ms/step\n",
      "Epoch 233/300\n",
      "step 1/1 - loss: 0.8021 - Perplexity: 1.0298 - 137ms/step\n",
      "Epoch 234/300\n",
      "step 1/1 - loss: 0.4953 - Perplexity: 1.0183 - 133ms/step\n",
      "Epoch 235/300\n",
      "step 1/1 - loss: 0.6281 - Perplexity: 1.0233 - 134ms/step\n",
      "Epoch 236/300\n",
      "step 1/1 - loss: 0.6121 - Perplexity: 1.0227 - 136ms/step\n",
      "Epoch 237/300\n",
      "step 1/1 - loss: 0.5624 - Perplexity: 1.0208 - 134ms/step\n",
      "Epoch 238/300\n",
      "step 1/1 - loss: 0.5162 - Perplexity: 1.0191 - 131ms/step\n",
      "Epoch 239/300\n",
      "step 1/1 - loss: 0.5536 - Perplexity: 1.0205 - 133ms/step\n",
      "Epoch 240/300\n",
      "step 1/1 - loss: 0.4423 - Perplexity: 1.0163 - 135ms/step\n",
      "Epoch 241/300\n",
      "step 1/1 - loss: 0.4784 - Perplexity: 1.0177 - 134ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/240\n",
      "Epoch 242/300\n",
      "step 1/1 - loss: 0.5405 - Perplexity: 1.0200 - 150ms/step\n",
      "Epoch 243/300\n",
      "step 1/1 - loss: 0.6368 - Perplexity: 1.0236 - 141ms/step\n",
      "Epoch 244/300\n",
      "step 1/1 - loss: 0.6239 - Perplexity: 1.0231 - 137ms/step\n",
      "Epoch 245/300\n",
      "step 1/1 - loss: 0.6498 - Perplexity: 1.0241 - 132ms/step\n",
      "Epoch 246/300\n",
      "step 1/1 - loss: 0.5089 - Perplexity: 1.0188 - 121ms/step\n",
      "Epoch 247/300\n",
      "step 1/1 - loss: 0.4542 - Perplexity: 1.0168 - 123ms/step\n",
      "Epoch 248/300\n",
      "step 1/1 - loss: 0.4800 - Perplexity: 1.0177 - 127ms/step\n",
      "Epoch 249/300\n",
      "step 1/1 - loss: 0.5698 - Perplexity: 1.0211 - 133ms/step\n",
      "Epoch 250/300\n",
      "step 1/1 - loss: 0.4438 - Perplexity: 1.0164 - 130ms/step\n",
      "Epoch 251/300\n",
      "step 1/1 - loss: 0.4720 - Perplexity: 1.0175 - 130ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/250\n",
      "Epoch 252/300\n",
      "step 1/1 - loss: 0.4155 - Perplexity: 1.0153 - 180ms/step\n",
      "Epoch 253/300\n",
      "step 1/1 - loss: 0.5841 - Perplexity: 1.0216 - 128ms/step\n",
      "Epoch 254/300\n",
      "step 1/1 - loss: 0.5943 - Perplexity: 1.0220 - 127ms/step\n",
      "Epoch 255/300\n",
      "step 1/1 - loss: 0.4337 - Perplexity: 1.0160 - 130ms/step\n",
      "Epoch 256/300\n",
      "step 1/1 - loss: 0.3657 - Perplexity: 1.0135 - 127ms/step\n",
      "Epoch 257/300\n",
      "step 1/1 - loss: 0.4052 - Perplexity: 1.0150 - 139ms/step\n",
      "Epoch 258/300\n",
      "step 1/1 - loss: 0.5050 - Perplexity: 1.0187 - 130ms/step\n",
      "Epoch 259/300\n",
      "step 1/1 - loss: 0.4390 - Perplexity: 1.0162 - 129ms/step\n",
      "Epoch 260/300\n",
      "step 1/1 - loss: 0.4784 - Perplexity: 1.0177 - 128ms/step\n",
      "Epoch 261/300\n",
      "step 1/1 - loss: 0.4567 - Perplexity: 1.0169 - 134ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/260\n",
      "Epoch 262/300\n",
      "step 1/1 - loss: 0.5221 - Perplexity: 1.0193 - 139ms/step\n",
      "Epoch 263/300\n",
      "step 1/1 - loss: 0.4941 - Perplexity: 1.0183 - 134ms/step\n",
      "Epoch 264/300\n",
      "step 1/1 - loss: 0.4762 - Perplexity: 1.0176 - 130ms/step\n",
      "Epoch 265/300\n",
      "step 1/1 - loss: 0.3904 - Perplexity: 1.0144 - 126ms/step\n",
      "Epoch 266/300\n",
      "step 1/1 - loss: 0.4825 - Perplexity: 1.0178 - 133ms/step\n",
      "Epoch 267/300\n",
      "step 1/1 - loss: 0.3425 - Perplexity: 1.0126 - 129ms/step\n",
      "Epoch 268/300\n",
      "step 1/1 - loss: 0.4282 - Perplexity: 1.0158 - 134ms/step\n",
      "Epoch 269/300\n",
      "step 1/1 - loss: 0.4436 - Perplexity: 1.0164 - 135ms/step\n",
      "Epoch 270/300\n",
      "step 1/1 - loss: 0.5384 - Perplexity: 1.0199 - 128ms/step\n",
      "Epoch 271/300\n",
      "step 1/1 - loss: 0.7401 - Perplexity: 1.0275 - 133ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/270\n",
      "Epoch 272/300\n",
      "step 1/1 - loss: 0.4013 - Perplexity: 1.0148 - 144ms/step\n",
      "Epoch 273/300\n",
      "step 1/1 - loss: 0.3818 - Perplexity: 1.0141 - 133ms/step\n",
      "Epoch 274/300\n",
      "step 1/1 - loss: 0.4052 - Perplexity: 1.0150 - 134ms/step\n",
      "Epoch 275/300\n",
      "step 1/1 - loss: 0.3483 - Perplexity: 1.0128 - 132ms/step\n",
      "Epoch 276/300\n",
      "step 1/1 - loss: 0.4978 - Perplexity: 1.0184 - 138ms/step\n",
      "Epoch 277/300\n",
      "step 1/1 - loss: 0.3950 - Perplexity: 1.0146 - 127ms/step\n",
      "Epoch 278/300\n",
      "step 1/1 - loss: 0.3814 - Perplexity: 1.0141 - 128ms/step\n",
      "Epoch 279/300\n",
      "step 1/1 - loss: 0.2887 - Perplexity: 1.0106 - 135ms/step\n",
      "Epoch 280/300\n",
      "step 1/1 - loss: 0.5362 - Perplexity: 1.0198 - 130ms/step\n",
      "Epoch 281/300\n",
      "step 1/1 - loss: 0.4169 - Perplexity: 1.0154 - 131ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/280\n",
      "Epoch 282/300\n",
      "step 1/1 - loss: 0.3010 - Perplexity: 1.0111 - 138ms/step\n",
      "Epoch 283/300\n",
      "step 1/1 - loss: 0.4326 - Perplexity: 1.0160 - 135ms/step\n",
      "Epoch 284/300\n",
      "step 1/1 - loss: 0.4730 - Perplexity: 1.0175 - 136ms/step\n",
      "Epoch 285/300\n",
      "step 1/1 - loss: 0.5579 - Perplexity: 1.0207 - 134ms/step\n",
      "Epoch 286/300\n",
      "step 1/1 - loss: 0.3830 - Perplexity: 1.0141 - 129ms/step\n",
      "Epoch 287/300\n",
      "step 1/1 - loss: 0.5304 - Perplexity: 1.0196 - 129ms/step\n",
      "Epoch 288/300\n",
      "step 1/1 - loss: 0.4137 - Perplexity: 1.0153 - 133ms/step\n",
      "Epoch 289/300\n",
      "step 1/1 - loss: 0.2927 - Perplexity: 1.0108 - 128ms/step\n",
      "Epoch 290/300\n",
      "step 1/1 - loss: 0.4769 - Perplexity: 1.0176 - 130ms/step\n",
      "Epoch 291/300\n",
      "step 1/1 - loss: 0.3372 - Perplexity: 1.0124 - 136ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/290\n",
      "Epoch 292/300\n",
      "step 1/1 - loss: 0.3399 - Perplexity: 1.0125 - 149ms/step\n",
      "Epoch 293/300\n",
      "step 1/1 - loss: 0.4487 - Perplexity: 1.0166 - 144ms/step\n",
      "Epoch 294/300\n",
      "step 1/1 - loss: 0.3143 - Perplexity: 1.0116 - 145ms/step\n",
      "Epoch 295/300\n",
      "step 1/1 - loss: 0.3518 - Perplexity: 1.0130 - 141ms/step\n",
      "Epoch 296/300\n",
      "step 1/1 - loss: 0.2940 - Perplexity: 1.0108 - 134ms/step\n",
      "Epoch 297/300\n",
      "step 1/1 - loss: 0.4029 - Perplexity: 1.0149 - 133ms/step\n",
      "Epoch 298/300\n",
      "step 1/1 - loss: 0.3618 - Perplexity: 1.0133 - 133ms/step\n",
      "Epoch 299/300\n",
      "step 1/1 - loss: 0.2229 - Perplexity: 1.0082 - 137ms/step\n",
      "Epoch 300/300\n",
      "step 1/1 - loss: 0.2998 - Perplexity: 1.0110 - 137ms/step\n",
      "save checkpoint at /home/aistudio/couplet_models/final\n"
     ]
    }
   ],
   "source": [
    "model = paddle.Model(\n",
    "    Seq2SeqAttnModel(vocab_size, hidden_size, hidden_size,\n",
    "                        num_layers, pad_id))\n",
    "\n",
    "optimizer = paddle.optimizer.Adam(\n",
    "    learning_rate=learning_rate, parameters=model.parameters())\n",
    "ppl_metric = Perplexity()\n",
    "model.prepare(optimizer, CrossEntropyCriterion(), ppl_metric)\n",
    "\n",
    "model.fit(train_data=train_loader,\n",
    "            epochs=max_epoch,\n",
    "            eval_freq=10,\n",
    "            save_freq=10,\n",
    "            save_dir=model_path,\n",
    "            log_freq=log_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测\n",
    "\n",
    "### 定义预测网络Seq2SeqAttnInferModel\n",
    "预测网络继承上面的主网络`Seq2SeqAttnModel`，定义子类`Seq2SeqAttnInferModel`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:59:27.730803Z",
     "iopub.status.busy": "2022-06-24T05:59:27.730323Z",
     "iopub.status.idle": "2022-06-24T05:59:27.742814Z",
     "shell.execute_reply": "2022-06-24T05:59:27.741993Z",
     "shell.execute_reply.started": "2022-06-24T05:59:27.730755Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqAttnInferModel(Seq2SeqAttnModel):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_dim,\n",
    "                 hidden_size,\n",
    "                 num_layers,\n",
    "                 bos_id=0,\n",
    "                 eos_id=1,\n",
    "                 beam_size=4,\n",
    "                 max_out_len=256):\n",
    "        self.bos_id = bos_id\n",
    "        self.beam_size = beam_size\n",
    "        self.max_out_len = max_out_len\n",
    "        self.num_layers = num_layers\n",
    "        super(Seq2SeqAttnInferModel, self).__init__(\n",
    "            vocab_size, embed_dim, hidden_size, num_layers, eos_id)\n",
    "\n",
    "        # Dynamic decoder for inference\n",
    "        self.beam_search_decoder = nn.BeamSearchDecoder(\n",
    "            self.decoder.lstm_attention.cell,\n",
    "            start_token=bos_id,\n",
    "            end_token=eos_id,\n",
    "            beam_size=beam_size,\n",
    "            embedding_fn=self.decoder.embedder,\n",
    "            output_fn=self.decoder.output_layer)\n",
    "\n",
    "    def forward(self, src, src_length):\n",
    "        encoder_output, encoder_final_state = self.encoder(src, src_length)\n",
    "\n",
    "        encoder_final_state = [\n",
    "            (encoder_final_state[0][i], encoder_final_state[1][i])\n",
    "            for i in range(self.num_layers)\n",
    "        ]\n",
    "\n",
    "        # Initial decoder initial states\n",
    "        decoder_initial_states = [\n",
    "            encoder_final_state,\n",
    "            self.decoder.lstm_attention.cell.get_initial_states(\n",
    "                batch_ref=encoder_output, shape=[self.hidden_size])\n",
    "        ]\n",
    "        # Build attention mask to avoid paying attention on paddings\n",
    "        src_mask = (src != self.eos_id).astype(paddle.get_default_dtype())\n",
    "\n",
    "        encoder_padding_mask = (src_mask - 1.0) * self.INF\n",
    "        encoder_padding_mask = paddle.unsqueeze(encoder_padding_mask, [1])\n",
    "\n",
    "        # Tile the batch dimension with beam_size\n",
    "        encoder_output = nn.BeamSearchDecoder.tile_beam_merge_with_batch(\n",
    "            encoder_output, self.beam_size)\n",
    "        encoder_padding_mask = nn.BeamSearchDecoder.tile_beam_merge_with_batch(\n",
    "            encoder_padding_mask, self.beam_size)\n",
    "\n",
    "        # Dynamic decoding with beam search\n",
    "        seq_output, _ = nn.dynamic_decode(\n",
    "            decoder=self.beam_search_decoder,\n",
    "            inits=decoder_initial_states,\n",
    "            max_step_num=self.max_out_len,\n",
    "            encoder_output=encoder_output,\n",
    "            encoder_padding_mask=encoder_padding_mask)\n",
    "        return seq_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码部分\n",
    "接下来对我们的任务选择beam search解码方式，可以指定beam_size为10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:59:27.744665Z",
     "iopub.status.busy": "2022-06-24T05:59:27.744156Z",
     "iopub.status.idle": "2022-06-24T05:59:27.930860Z",
     "shell.execute_reply": "2022-06-24T05:59:27.930140Z",
     "shell.execute_reply.started": "2022-06-24T05:59:27.744622Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def post_process_seq(seq, bos_idx, eos_idx, output_bos=False, output_eos=False):\n",
    "    \"\"\"\n",
    "    Post-process the decoded sequence.\n",
    "    \"\"\"\n",
    "    eos_pos = len(seq) - 1\n",
    "    for i, idx in enumerate(seq):\n",
    "        if idx == eos_idx:\n",
    "            eos_pos = i\n",
    "            break\n",
    "    seq = [\n",
    "        idx for idx in seq[:eos_pos + 1]\n",
    "        if (output_bos or idx != bos_idx) and (output_eos or idx != eos_idx)\n",
    "    ]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:59:27.932428Z",
     "iopub.status.busy": "2022-06-24T05:59:27.931981Z",
     "iopub.status.idle": "2022-06-24T05:59:27.945859Z",
     "shell.execute_reply": "2022-06-24T05:59:27.945364Z",
     "shell.execute_reply.started": "2022-06-24T05:59:27.932399Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beam_size = 10\n",
    "model = paddle.Model(\n",
    "    Seq2SeqAttnInferModel(\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        bos_id=bos_id,\n",
    "        eos_id=eos_id,\n",
    "        beam_size=beam_size,\n",
    "        max_out_len=256))\n",
    "\n",
    "model.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在预测之前，我们需要将训练好的模型参数load进预测网络，之后我们就可以根据自然语言文具，生成对应的sparql啦！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:59:27.946884Z",
     "iopub.status.busy": "2022-06-24T05:59:27.946662Z",
     "iopub.status.idle": "2022-06-24T05:59:28.199403Z",
     "shell.execute_reply": "2022-06-24T05:59:28.198700Z",
     "shell.execute_reply.started": "2022-06-24T05:59:27.946862Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load('couplet_models/final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-24T05:59:28.200986Z",
     "iopub.status.busy": "2022-06-24T05:59:28.200521Z",
     "iopub.status.idle": "2022-06-24T05:59:28.481301Z",
     "shell.execute_reply": "2022-06-24T05:59:28.480728Z",
     "shell.execute_reply.started": "2022-06-24T05:59:28.200958Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问: 煤炭行业有多少上市公司\tsparql: select ( count ( distinct ?result ) as ?count ) where { ?n1 sct:hasChineseLabel \"煤炭行业\" . ?n1 rdfs: ?result . }\n",
      "\n",
      "问: 乐凯胶片的股票id是多少\tsparql: select ?result where { ?n1 sct:hasChineseLabel \"乐凯胶片\" . ?n1 sct:ID ?result . }\n",
      "\n",
      "问: 太原重工属于哪个行业\tsparql: select ?result where { ?n1 sct:hasChineseLabel ?result . ?n1 rdfs: ?n2 . ?n2 sct:hasChineseLabel \"太原重工\" . }\n",
      "\n",
      "问: 上市公司最多的行业是什么\tsparql: select ?result where { { select ?n1 ( count ( ?n2 ) as ?subresult ) where { zg:SinaFinance rdfs: ?n1 . ?n1 rdfs: ?n2 . } group by ?n1 } ?n1 sct:hasChineseLabel ?result . } order by desc ( ?subresult ) limit 1\n",
      "\n",
      "问: 上市公司最少的5个行业是什么\tsparql: select ?result where { { select ?n1 ( count ( ?n2 ) as ?subresult ) where { zg:SinaFinance rdfs: ?n1 . ?n1 rdfs: ?n2 . } group by ?n1 } ?n1 sct:hasChineseLabel ?result . } order by desc ( ?subresult ) limit 1\n",
      "\n",
      "问: 上市公司最多的前3个行业的公司数目各是多少\tsparql: select ?result where { select ( count ( ?n2 ) as ?result ) where { zg:SinaFinance rdfs: ?n1 . ?n1 rdfs: ?n2 . } group by ?n1 } order by desc ( ?result ) limit 3\n",
      "\n",
      "问: 澳柯玛\tsparql: select ?p ?result where { ?n1 sct:hasChineseLabel \"澳柯玛\" . ?n1 ?p ?result . }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "trg_idx2word[1]='<start>'\n",
    "trg_idx2word[2]='<end>'\n",
    "for data in test_loader():\n",
    "    inputs = data[:2]\n",
    "    finished_seq = model.predict_batch(inputs=list(inputs))[0]\n",
    "    finished_seq = finished_seq[:, :, np.newaxis] if len(\n",
    "        finished_seq.shape) == 2 else finished_seq\n",
    "    finished_seq = np.transpose(finished_seq, [0, 2, 1])\n",
    "    for ins in finished_seq:\n",
    "        for beam in ins:\n",
    "            id_list = post_process_seq(beam, bos_id, eos_id)\n",
    "            word_list_f = [trg_idx2word[id] for id in test_ds[idx][0]][1:-1]\n",
    "            word_list_s = [trg_idx2word[id] for id in id_list]\n",
    "            sequence = \"问: \"+\"\".join(word_list_f)+\"\\tsparql: \"+\" \".join(word_list_s).replace('sct:haschineselabel','sct:hasChineseLabel').replace('sct:id','sct:ID').replace('zg:sinafinance','zg:SinaFinance') + \"\\n\"\n",
    "            print(sequence)\n",
    "            idx += 1\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
